{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TFLite_FashionMnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8-Nr5k11fh"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Eq10uEbw0E4l"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06ndLauQxiQm"
      },
      "source": [
        "# Train Your Own Model and Convert It to TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtav_aq2xh6n"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%202%20-%20TensorFlow%20Lite/Week%201/Exercises/TFLite_Week1_Exercise.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%202%20-%20TensorFlow%20Lite/Week%201/Exercises/TFLite_Week1_Exercise.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka96-ajYzxVU"
      },
      "source": [
        "This notebook uses the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "Fashion MNIST is intended as a drop-in replacement for the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset—often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc.) in a format identical to that of the articles of clothing we'll use here.\n",
        "\n",
        "This uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code.\n",
        "\n",
        "We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow. Import and load the Fashion MNIST data directly from TensorFlow:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjOAfhgd__Sp"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp_nvHnh_tDo"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfyZKowNAQ4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b451f9a8-20c9-4b9e-dda6-6261bcbb5ad8"
      },
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "\n",
        "print('\\u2022 Using TensorFlow Version:', tf.__version__)\n",
        "print('\\u2022 GPU Device Found.' if tf.test.is_gpu_available() else '\\u2022 GPU Device Not Found. Running on CPU')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "• Using TensorFlow Version: 2.5.0\n",
            "WARNING:tensorflow:From <ipython-input-2-adb891da5723>:11: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "• GPU Device Found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tadPBTEiAprt"
      },
      "source": [
        "# Download Fashion MNIST Dataset\n",
        "\n",
        "We will use TensorFlow Datasets to load the Fashion MNIST dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwjhNzzXI9w5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d236cf89-91f6-4515-a3dd-c851614e0e00"
      },
      "source": [
        "whole_ds,info_ds = tfds.load(\"fashion_mnist\", with_info = True, split='train+test', as_supervised=True) #60,000+10,000\n",
        "\n",
        "n = tf.data.experimental.cardinality(whole_ds).numpy() # 70,000\n",
        "train_num = int(n*0.8) #56,000\n",
        "val_num = int(n*0.1) #7000\n",
        "\n",
        "train_examples = whole_ds.take(train_num)\n",
        "validation_examples = whole_ds.skip(train_num).take(val_num)\n",
        "test_examples = whole_ds.skip(train_num+val_num) #7000\n",
        "\n",
        "num_examples = train_num\n",
        "num_classes = info_ds.features['label'].num_classes"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset fashion_mnist/3.0.1 (download: 29.45 MiB, generated: 36.42 MiB, total: 65.87 MiB) to /root/tensorflow_datasets/fashion_mnist/3.0.1...\u001b[0m\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/fashion_mnist/3.0.1.incompleteGE657U/fashion_mnist-train.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/fashion_mnist/3.0.1.incompleteGE657U/fashion_mnist-test.tfrecord\n",
            "\u001b[1mDataset fashion_mnist downloaded and prepared to /root/tensorflow_datasets/fashion_mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhwV_Q2da3Hn"
      },
      "source": [
        "The class names are not included with the dataset, so we will specify them here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eAv71FRm4JE"
      },
      "source": [
        "class_names = ['T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXe6jNokqX3_"
      },
      "source": [
        "# Create a labels.txt file with the class names\n",
        "with open('labels.txt', 'w') as f:\n",
        "    f.write('\\n'.join(class_names))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iubWCThbdN8K"
      },
      "source": [
        "# The images in the dataset are 28 by 28 pixels.\n",
        "IMG_SIZE = 28"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAkuq0V0Aw2X"
      },
      "source": [
        "# Preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5SIivkunKCC"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwyhsyGydHDl"
      },
      "source": [
        "def format_example(image, label):\n",
        "    # Cast image to float32\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "        \n",
        "    # Normalize the image in the range [0, 1]\n",
        "    image = image/255\n",
        "    \n",
        "    return image, tf.one_hot(label, num_classes)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAlBlXOUMwqe"
      },
      "source": [
        "# Specify the batch size\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM4HfIJtnNEk"
      },
      "source": [
        "## Create Datasets From Images and Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxe2I3oxLDhq"
      },
      "source": [
        "# Create Datasets\n",
        "train_batches = train_examples.cache().shuffle(num_examples//4).batch(BATCH_SIZE).map(format_example).prefetch(1)\n",
        "validation_batches = validation_examples.cache().batch(BATCH_SIZE).map(format_example)\n",
        "test_batches = test_examples.batch(1).map(format_example)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-topQaOm_LM"
      },
      "source": [
        "# Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GTUPWera3Hp"
      },
      "source": [
        "```\n",
        "Model: \"sequential\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
        "_________________________________________________________________\n",
        "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
        "_________________________________________________________________\n",
        "flatten (Flatten)            (None, 3872)              0         \n",
        "_________________________________________________________________\n",
        "dense (Dense)                (None, 64)                247872    \n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 10)                650       \n",
        "=================================================================\n",
        "Total params: 253,322\n",
        "Trainable params: 253,322\n",
        "Non-trainable params: 0\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDqcwksFB1bh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b5ab0b-fa29-4ef5-ac5f-17afe0f60133"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    # Set the input shape to (28, 28, 1), kernel size=3, filters=16 and use ReLU activation,\n",
        "    tf.keras.layers.Conv2D(input_shape=(28,28,1), kernel_size=3, filters=16, activation='relu'),\n",
        "      \n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "      \n",
        "    # Set the number of filters to 32, kernel size to 3 and use ReLU activation \n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
        "      \n",
        "    # Flatten the output layer to 1 dimension\n",
        "    tf.keras.layers.Flatten(),\n",
        "      \n",
        "    # Add a fully connected layer with 64 hidden units and ReLU activation\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "      \n",
        "    # Attach a final softmax classification head\n",
        "    tf.keras.layers.Dense(activation='softmax', units=num_classes)])\n",
        "\n",
        "# Set the appropriate loss function and use accuracy as your metric\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics='accuracy')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3872)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                247872    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 253,322\n",
            "Trainable params: 253,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEMOz-LDnxgD"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGlNoRtzCP4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b8131e0-cbed-4406-c67b-fb326b392220"
      },
      "source": [
        "model.fit(train_batches, \n",
        "          epochs=10,\n",
        "          validation_data=validation_batches)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "219/219 [==============================] - 24s 36ms/step - loss: 1.3716 - accuracy: 0.5357 - val_loss: 0.7563 - val_accuracy: 0.7110\n",
            "Epoch 2/10\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7111 - accuracy: 0.7321 - val_loss: 0.6533 - val_accuracy: 0.7499\n",
            "Epoch 3/10\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.6500 - accuracy: 0.7548 - val_loss: 0.6216 - val_accuracy: 0.7680\n",
            "Epoch 4/10\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.6163 - accuracy: 0.7686 - val_loss: 0.6020 - val_accuracy: 0.7707\n",
            "Epoch 5/10\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.5878 - accuracy: 0.7807 - val_loss: 0.5515 - val_accuracy: 0.7906\n",
            "Epoch 6/10\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.5632 - accuracy: 0.7897 - val_loss: 0.5389 - val_accuracy: 0.7866\n",
            "Epoch 7/10\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.5442 - accuracy: 0.7977 - val_loss: 0.5199 - val_accuracy: 0.8063\n",
            "Epoch 8/10\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.5264 - accuracy: 0.8047 - val_loss: 0.4976 - val_accuracy: 0.8173\n",
            "Epoch 9/10\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.5101 - accuracy: 0.8132 - val_loss: 0.4863 - val_accuracy: 0.8179\n",
            "Epoch 10/10\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.4982 - accuracy: 0.8164 - val_loss: 0.4777 - val_accuracy: 0.8274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f49461de2d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZT9-7w9n4YO"
      },
      "source": [
        "# Exporting to TFLite\n",
        "\n",
        "You will now save the model to TFLite. We should note, that you will probably see some warning messages when running the code below. These warnings have to do with software updates and should not cause any errors or prevent your code from running. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dq78KBkCV2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b14b633-6cdc-4b54-ceeb-0fe85f0f6dff"
      },
      "source": [
        "# EXERCISE: Use the tf.saved_model API to save your model in the SavedModel format. \n",
        "export_dir = 'saved_model/1'\n",
        "\n",
        "tf.saved_model.save(model, export_dir)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/1/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDGiYrBdE6fl",
        "cellView": "form"
      },
      "source": [
        "#@title Select mode of optimization\n",
        "mode = \"Speed\" #@param [\"Default\", \"Storage\", \"Speed\"]\n",
        "\n",
        "if mode == 'Storage':\n",
        "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE\n",
        "elif mode == 'Speed':\n",
        "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n",
        "else:\n",
        "    optimization = tf.lite.Optimize.DEFAULT"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbcS9C00CzGe"
      },
      "source": [
        "# EXERCISE: Use the TFLiteConverter SavedModel API to initialize the converter\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "\n",
        "# Set the optimzations\n",
        "converter.optimizations = [optimization]\n",
        "\n",
        "# Invoke the converter to finally generate the TFLite model\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5PWCDsTC3El",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c7e840-03fa-4d68-f9bf-d639e03b9cc6"
      },
      "source": [
        "tflite_model_file = pathlib.Path('./model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "259904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR6wFcQ1Fglm"
      },
      "source": [
        "# Test the Model with TFLite Interpreter "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKcToCBEC-Bu"
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8EpFpIBFkq8"
      },
      "source": [
        "# Gather results for the randomly sampled test images\n",
        "predictions = []\n",
        "test_labels = []\n",
        "test_images = []\n",
        "\n",
        "for img, label in test_batches.take(50):\n",
        "    interpreter.set_tensor(input_index, img)\n",
        "    interpreter.invoke()\n",
        "    predictions.append(interpreter.get_tensor(output_index))\n",
        "    test_labels.append(label[0])\n",
        "    test_images.append(np.array(img))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSjTmi05Tyod"
      },
      "source": [
        "#@title Utility functions for plotting\n",
        "# Utilities for plotting\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    img = np.squeeze(img)\n",
        "    \n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "    \n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    print(predicted_label, np.argmax(true_label.numpy()))\n",
        "\n",
        "    if predicted_label == np.argmax(true_label.numpy()):\n",
        "        color = 'green'\n",
        "    else:\n",
        "        color = 'red'\n",
        "    \n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                         100*np.max(predictions_array),\n",
        "                                         class_names[true_label]), color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks(list(range(10)), class_names, rotation='vertical')\n",
        "    plt.yticks([])\n",
        "    thisplot = plt.bar(range(10), predictions_array[0], color=\"#777777\")\n",
        "    plt.ylim([0, 1])\n",
        "    predicted_label = np.argmax(predictions_array[0])\n",
        "\n",
        "    thisplot[predicted_label].set_color('red')\n",
        "    thisplot[true_label].set_color('green')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZwg0wFaVXhZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "75f03424-b0ae-4068-b306-f58684b00e2d"
      },
      "source": [
        "#@title Visualize the outputs { run: \"auto\" }\n",
        "index = 33 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(index, predictions, tf.argmax(test_labels, axis=1), test_images)\n",
        "plt.show()\n",
        "plot_value_array(index, predictions, tf.argmax(test_labels, axis=1))\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "076bo3FMpRDb"
      },
      "source": [
        "# Download the TFLite Model and Assets\n",
        "\n",
        "If you are running this notebook in a Colab, you can run the cell below to download the tflite model and labels to your local disk.\n",
        "\n",
        "**Note**: If the files do not download when you run the cell, try running the cell a second time. Your browser might prompt you to allow multiple files to be downloaded. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsPXqPlgZPjE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "0b18b69a-9b1d-4143-be41-dbe8a437cc29"
      },
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    \n",
        "    files.download(tflite_model_file)\n",
        "    files.download('labels.txt')\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2920622f-dfa4-4bb0-80ab-4e6a0470a792\", \"model.tflite\", 259904)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_aec46e79-b06c-41ca-a63b-093035eaa8c0\", \"labels.txt\", 75)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8t7_jRiz9Vw"
      },
      "source": [
        "# Prepare the Test Images for Download (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi09nIps0gBu"
      },
      "source": [
        "!mkdir -p test_images"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v-MF-6pWKQM",
        "outputId": "b766ff4e-7066-4a06-b02d-f541527cbf34"
      },
      "source": [
        "tf.argmax(label, 1).numpy()[0]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF7EZ63J0hZs"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "for index, (image, label) in enumerate(test_batches.take(50)):\n",
        "    image = tf.cast(image * 255.0, tf.uint8)\n",
        "    image = tf.squeeze(image).numpy()\n",
        "    pil_image = Image.fromarray(image)\n",
        "    pil_image.save('test_images/{}_{}.jpg'.format(class_names[tf.argmax(label, 1).numpy()[0]].lower(), index))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM35O-uv0iWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa2d31e-2256-4992-bc4a-1745b4d6a4cc"
      },
      "source": [
        "!ls test_images"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'ankle boot_0.jpg'    coat_35.jpg       pullover_14.jpg   trouser_21.jpg\n",
            "'ankle boot_15.jpg'   coat_37.jpg       pullover_16.jpg   trouser_36.jpg\n",
            "'ankle boot_24.jpg'   coat_49.jpg       pullover_26.jpg   trouser_42.jpg\n",
            "'ankle boot_27.jpg'   coat_4.jpg        pullover_30.jpg   t-shirt_top_28.jpg\n",
            "'ankle boot_45.jpg'   coat_7.jpg        pullover_32.jpg   t-shirt_top_29.jpg\n",
            " bag_19.jpg\t      dress_11.jpg      sandal_9.jpg\t  t-shirt_top_34.jpg\n",
            " bag_2.jpg\t      dress_1.jpg       shirt_17.jpg\t  t-shirt_top_39.jpg\n",
            " bag_31.jpg\t      dress_25.jpg      shirt_22.jpg\t  t-shirt_top_41.jpg\n",
            " bag_38.jpg\t      dress_3.jpg       shirt_33.jpg\t  t-shirt_top_44.jpg\n",
            " bag_43.jpg\t      dress_40.jpg      shirt_46.jpg\t  t-shirt_top_5.jpg\n",
            " bag_48.jpg\t      dress_47.jpg      sneaker_18.jpg\t  t-shirt_top_8.jpg\n",
            " coat_13.jpg\t      pullover_10.jpg   sneaker_20.jpg\n",
            " coat_23.jpg\t      pullover_12.jpg   sneaker_6.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR20r4qW0jVm"
      },
      "source": [
        "!zip -qq fmnist_test_images.zip -r test_images/"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxsZEI51a3Ht"
      },
      "source": [
        "If you are running this notebook in a Colab, you can run the cell below to download the Zip file with the images to your local disk. \n",
        "\n",
        "**Note**: If the Zip file does not download when you run the cell, try running the cell a second time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjk4537X0kWN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "7bf2e350-ed3c-4f46-b540-5b8fa0823e2e"
      },
      "source": [
        "try:\n",
        "    files.download('fmnist_test_images.zip')\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_90fcf252-9178-4795-8bdd-0752f74d86be\", \"fmnist_test_images.zip\", 25830)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}